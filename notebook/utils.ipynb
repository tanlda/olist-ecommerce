{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502024a9-cada-4403-8abd-fb362d72503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import duckdb\n",
    "import requests\n",
    "import polars as pl\n",
    "import pyiceberg as pi\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from faker import Faker\n",
    "from minio import Minio\n",
    "from unidecode import unidecode\n",
    "from types import SimpleNamespace\n",
    "from tempfile import NamedTemporaryFile\n",
    "from pyiceberg.catalog import load_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814b3a36-b756-495b-b907-6b54d43df21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "\n",
    "def get_storage(host: str):\n",
    "    client = Minio(endpoint=host, access_key=\"admin\", secret_key=\"password\", secure=False)\n",
    "    return client\n",
    "\n",
    "def get_storage_options(host: str, fs: bool=False):\n",
    "    if fs:\n",
    "        options = {\n",
    "            \"key\": \"admin\",\n",
    "            \"secret\": \"password\",\n",
    "            \"client_kwargs\": {\n",
    "                \"region_name\": \"us-east-1\",\n",
    "                \"endpoint_url\": \"http://\" + host,\n",
    "                \"verify\": False\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        options = {\n",
    "            \"aws_access_key_id\": \"admin\",\n",
    "            \"aws_secret_access_key\": \"password\",\n",
    "            \"aws_endpoint_url\": \"http://\" + host,\n",
    "            \"region_name\": \"us-east-1\",\n",
    "        }\n",
    "    return options\n",
    "\n",
    "\n",
    "get_storage.options = get_storage_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af787adf-871d-4438-a42e-ca43fbbe1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy as sa\n",
    "\n",
    "def get_database(host: str):\n",
    "    engine = sa.create_engine(f\"postgresql://admin:password@{host}:5432/ecommerce\")\n",
    "    return engine\n",
    "    \n",
    "def get_database_url(host: str, autocommit=False):\n",
    "    return f\"postgresql://admin:password@{host}:5432/ecommerce\"\n",
    "\n",
    "def get_database_pg(host: str, autocommit=False):\n",
    "    conn = psycopg2.connect(host=f\"{host}.io\", port=5432, user=\"admin\", password=\"password\", dbname=\"ecommerce\")\n",
    "    conn.autocommit = autocommit\n",
    "    return conn\n",
    "\n",
    "get_database.pg = get_database_pg\n",
    "get_database.url = get_database_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8868a88-c8c7-4fc8-a72c-ac11d6525086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "def get_document(host: str):\n",
    "    client = MongoClient(f\"mongodb://admin:password@{host}:27017/admin\")\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf71727-8e33-4f37-91e7-fe49a6319afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trino.dbapi import connect\n",
    "\n",
    "def get_trino(catalog: str, schema: str=\"public\"):\n",
    "    connection = connect(host=\"trino.sql\", port=80, user=\"admin\", catalog=catalog, schema=\"public\")\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8568574-6abb-448f-acb2-0da5ceda59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook: 192.168.1.88\n",
    "# Spark Web UI: 192.168.1.88:4040\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def get_spark(mode: str = \"local\", catalog: str = \"\", storage: str = \"\"):\n",
    "    session = SparkSession.builder.appName(\"notebook\")\n",
    "\n",
    "    if mode == \"client\":\n",
    "        session = (\n",
    "            session\n",
    "            .master(\"k8s://https://kubernetes.default.svc.cluster.local:443\")\n",
    "            .config(\"spark.driver.memory\", \"2G\")\n",
    "            .config(\"spark.executor.cores\", \"1\")\n",
    "            .config(\"spark.executor.memory\", \"2G\")\n",
    "            .config(\"spark.executor.instances\", \"2\")\n",
    "            .config(\"spark.kubernetes.namespace\", \"spark\")\n",
    "            .config(\"spark.kubernetes.container.image\", \"registry.io/spark\")\n",
    "            .config(\"spark.submit.deployMode\", \"client\")\n",
    "            .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "            .config(\"spark.driver.host\", \"notebook-headless.io\")\n",
    "        )\n",
    "\n",
    "    if catalog:\n",
    "        session = (\n",
    "            session\n",
    "            .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "            .config(\"spark.sql.defaultCatalog\", \"iceberg\")\n",
    "            .config(\"spark.sql.catalog.iceberg.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "            .config(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "            .config(\"spark.sql.catalog.iceberg.type\", \"rest\")\n",
    "            .config(\"spark.sql.catalog.iceberg.uri\", \"http://iceberg.io\")\n",
    "            .config(\"spark.sql.catalog.iceberg.warehouse\", \"s3://ecommerce/iceberg/\")\n",
    "            .config(\"spark.sql.catalog.iceberg.client.region\", \"us-east-1\")\n",
    "            .config(\"spark.sql.catalog.iceberg.s3.access-key-id\", \"admin\")\n",
    "            .config(\"spark.sql.catalog.iceberg.s3.secret-access-key\", \"password\")\n",
    "            .config(\"spark.sql.catalog.iceberg.s3.endpoint\", \"http://lakehouse.io\")\n",
    "            .config(\"spark.sql.catalog.iceberg.s3.path-style-access\", \"true\")\n",
    "        )\n",
    "\n",
    "    if storage:\n",
    "        session = (\n",
    "            session\n",
    "            .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "            .config(\"spark.hadoop.fs.s3a.secret.key\", \"password\")\n",
    "            .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://{storage}\")\n",
    "            .config(\"spark.hadoop.fs.s3a.endpoint.region\", \"us-east-1\")\n",
    "            .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "            .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "            .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "            .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "        )\n",
    "\n",
    "    spark = session.getOrCreate()\n",
    "    return spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
